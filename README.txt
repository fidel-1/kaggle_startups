Название тетрадки Startups_predictions_Chatuev_oc_71694_backup.ipynb

Отчет по итогам исследования:
Цель проекта - разработать модель для предсказания успешности стартапа (закроется или нет).

Дополнительные задачи проекта:

Выделить важные компоненты из данных, влияющие на работу стартапов.
На основе данных и графиков сформулировать рекомендации позволяющие повысить шанс на успех стартапа.
Подготовить отчет по исследованию.
Источники данных

Тренировочный набор (около 53к записей). Набор содержит целевой признак status, указывающий на то, закрылся стартап или продолжает действовать. Временной период - '1970-01-01' по '2018-01-01'. Дата формирования выгрузки - '2018-01-01' kaggle_startups_train_01.csv - информация (53 000) стартапах, которые будут использоваться в качестве обучающих данных. Тестовый набор. kaggle_startups_test_01.csv - информация (13 000) стартапах, которые будут использоваться в качестве тестовых данных. Ваша задача - предсказать значение 'status' для каждого стартапа из этого датасета. kaggle_startups_sample_submit_01.csv - файл с примером предсказаний в правильном формате. name - идентификатор (название) стартапа в тестовом наборе. status - целевой признак. Для каждого стартапа предскажите категориальное значение соответствующее прогнозу ['operating', 'closed'].

Реализованые шаги проекта:

4.1 Загружены данные, проведена проверка признаков описанию.

4.2 Предварительная обработка данных. Устранены пропуски и дубликаты. Форматы приведены в соответствие. Укрупнен категориальный признак category_list данные записаны в столбец yc_category. Данные признака last_funding_at преобразованы в числовой формат и записаны в отдельный столбец last_funding_at_days.

4.3 Проведен разведочный анализ, в том числе стат анализ количественных признаков и их распределений в разрезе целевого признака. Для действующих стартапов наблюдаем чуть более высокие значения медианы и среднего.

4.4 Разработаны новые синтетические признаки

разница в днях между последним раундом и датой выгрузки
соотношение между числом дней с последнего рауда и даты выгрузки / life_time
разница в днях между первым и последним раундом
средний чек привлечения
количество раундов на 1 год существования
средняя скорость привлечения денег в день
разница между датой основания и первым привлечением. Признак, допускающий утечку (не используется в обучении).
4.5. Проведена проверка признаков на мультиколлинеарность, по итогам которой проведен финальный отбор обучающих признаков.

4.6 Собран пайплан обработки данных и перебора гиперпараметров.

4.7 Проведена итоговая оценка качества предсказания лучшей модели на кросс-вадидации.

4.8 Сформированы предсказания на тестовом датасете

4.9. Проведен анализ важности признаков лучшей модели.

4.10. Подготовлен профиль действующего стартапа.

4.11 Подготовлен отчет по исследованию.

Использованные модели.
Используемые версии библиотек на которых удалось реализовать пайплайн scikit-learn==1.3.0 optuna==3.6.1
В предыдущих версиях проекта были попробованы

DecisionTreeClassifier с диапазоном гиперпараметров 'models__max_depth': range(2, 6), 'models__max_features': range(2, 6),
KNeighborsClassifier с диапазоном гиперпараметров 'models__n_neighbors': range(2, 10)
SVC
LogisticRegression 'models__C': range(1, 5) Однако, во всех случаях наилучих результатов удавалось получить используя HistGradientBoostingClassifier с диапазоном гиперпараметров 'models__max_iter': range(50, 200, 50), 'models__learning_rate': [0.01, 0.1, 0.2], В пайплайне итоговой версии проекта используется именно этот класс моделей.
Выводы и рекомендации: Сформулируем профиль действующего стартапа:



Предложения по улучшению модели:

Использовать более точные методы работы с текстом для более точного и распеределенного укрупнения категорий (LLM-решения)
Использовать методы автоматической генерации синтетических признаков
Применить иные метоты оценки отбора признаков, например SelectKBest.
Использовать семплеры для устранения дисбаланса классов.
Посмотреть статьи и отчеты по теме "жизнеспособности" стартапов для обогащения данными/нестандартного решения задачи.